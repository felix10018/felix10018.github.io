(window.webpackJsonp=window.webpackJsonp||[]).push([[103],{596:function(s,t,n){"use strict";n.r(t);var a=n(30),e=Object(a.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("p",[s._v("专题：collections容器数据类型")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n源代码： Lib/collections/__init__.py\n这个模块实现了一些专门化的容器，提供了对 Python 的通用内建容器dict、list、set 和tuple 的补充。\ncollections.nametupled()\ncollections.deque\ncollections.ChainMap\ncollections.Couter\ncollections.OrderedDict\ncollections.defaultdict\ncollections.UserDict\ncollections.UserList\ncollections.UserString\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("## 【1】collections.ChainMap 字典链表")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\ncollections.ChainMap 是 Python 标准库中 collections 模块提供的一个数据类型，它用于将多个字典或映射链接在一起形成一个逻辑上的整体。\n\nChainMap 提供了一种方便的方式来同时访问和操作这些链接的字典，它会按照链接的顺序依次查找键。可以将 ChainMap 理解为一个字典的链表，每个字典都是链表中的一个节点。当在 ChainMap 中查找键时，它会从链表的头部开始依次查找，直到找到第一个匹配的键为止。如果键在多个字典中都存在，则返回第一个匹配的键对应的值。\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" collections\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建两个字典")]),s._v("\ndict1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ndict2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建 ChainMap")]),s._v("\nchain_map "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" collections"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ChainMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dict1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dict2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问键 'a' 的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问键 'b' 的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 2（在 dict1 中找到了匹配的键 'b'）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问键 'c' 的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 4（在 dict2 中找到了匹配的键 'c'）")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 修改键 'b' 的值")]),s._v("\nchain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 修改后，字典dict1也会被该改变")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看修改后的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 5")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 遍历 ChainMap 中的所有键值对")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"dict1:"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("dict1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"dict2:"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("dict2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'*'")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndict1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ndict2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ndict3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'e'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'f'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\nchain_map "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" collections"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ChainMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dict1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dict2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# chain_map1 = collections.ChainMap(dict1, dict2,dict3)")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 按链接的字典顺序遍历")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一个ChainMap() 的迭代顺序是通过【从后往前】扫描所有映射来确定的:dict2--\x3edict1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" chain_map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# d-c-a-b")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" argparse\ndefaults "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'color'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'red'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'user'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'guest'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\nparser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" argparse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ArgumentParser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nparser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'-u'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'--user'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nparser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_argument"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'-c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'--color'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nnamespace "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" parser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parse_args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"namespace:"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("namespace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"os.environ:"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("environ"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ncommand_line_args "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" v "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" v "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("vars")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("namespace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" v "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ncombined "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" collections"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ChainMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("command_line_args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" os"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("environ"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" defaults"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("combined"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'color'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("combined"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'user'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("combined"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ALLUSERSPROFILE'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n【2】collections.Counter\nclass collections.Counter([iterable-or-mapping ])\nCounter 是dict 的子类，用于计数hashable 对象。它是一个多项集，元素存储为字典的键而它们\n的计数存储为字典的值。计数可以是任何整数，包括零或负的计数值。\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Counter\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建 Counter 对象")]),s._v("\nc "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Counter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 计数结果")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Counter({'a': 3, 'b': 2, 'c': 1})")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问元素计数")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 计数更新")]),s._v("\nc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Counter({'a': 4, 'b': 3, 'c': 1, 'd': 1})")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 合并计数器")]),s._v("\nc2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Counter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nc "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" c2\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Counter({'a': 5, 'b': 5, 'c': 2, 'd': 1})")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 常见元素")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("most_common"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [('a', 5), ('b', 5)]")]),s._v("\n\n\nc "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Counter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("a"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" c"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" d"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nres "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sorted")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("c"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("elements"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ['a', 'a', 'a', 'a', 'b', 'b']")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n【3】collections.deque \ncollections.deque是 Python 标准库中的一个双向队列（double-ended queue）类，它提供了高效的插入和删除操作，可以在队列的两端进行操作。\n\ncollections.deque 类的一些重要特性和用法：\n\n1-双向队列：deque 对象是一个双向队列，支持从队列的两端进行插入和删除操作。\n--在队列的左侧使用 appendleft() 方法插入元素，在右侧使用 append() 方法插入元素。\n--可以在左侧使用 popleft() 方法移除元素，在右侧使用 pop() 方法移除元素。\n\n2-限制队列长度：可以通过指定 maxlen 参数来创建一个有限长度的队列。\n一旦队列达到最大长度，在插入元素时会自动移除队列的最早元素。如果不指定 maxlen 参数，则队列可以无限增长。\n\n3-高效操作：deque 对象的插入和删除操作在两端都是高效的，时间复杂度为 O(1)。\n这使得它在需要频繁插入和删除元素的场景中比列表更加高效。\n\n3-可迭代性：deque 对象可以像列表一样进行迭代操作\n可以使用 for 循环遍历队列中的元素，也可以使用切片等操作\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" deque\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建空的 deque 对象")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" deque"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在右侧插入元素")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在左侧插入元素")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("appendleft"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'z'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 遍历 deque 对象")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" item "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：'z', 'a', 'b', 'c'")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 移除右侧元素")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# deque(['z', 'a', 'b'])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 移除左侧元素")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("popleft"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# deque(['a', 'b'])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建有限长度的 deque 对象")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" deque"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("maxlen"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自动移除最早的元素 1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# deque([2, 3, 4])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n【4】collections.defaultdict\ncollections.defaultdict 是 Python 标准库中的一个字典类，它是 dict 的子类。\n与普通的字典不同，defaultdict 允许指定一个默认值（default value），以便在访问不存在的键时返回该默认值，而不会引发 KeyError 异常。\n\ncollections.defaultdict 类的一些重要特性和用法：\n--1、默认值工厂函数：defaultdict 接受一个工厂函数作为参数，在访问不存在的键时会调用该工厂函数以生成默认值。\n工厂函数可以是任何可调用对象，如内置函数、自定义函数或类的构造函数。\n\n--2、自动创建键：如果访问一个不存在的键，defaultdict 会使用默认值工厂函数生成一个默认值，并将其与该键关联起来。\n这样，即使字典中原本不存在该键，也可以直接访问并获取默认值。\n\n--3、方便使用：defaultdict 的行为与普通字典完全一致，因此你可以像使用普通字典一样使用它。\n它支持常见的字典操作，如访问键、设置键值对、删除键等。\n"""')]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" defaultdict\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建默认值为 0 的 defaultdict 对象")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" defaultdict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问不存在的键，默认值为 0")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 0")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自动创建键，并更新默认值")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# defaultdict(<class 'int'>, {'a': 1, 'b': 2})")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建默认值为空列表的 defaultdict 对象")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" defaultdict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问不存在的键，默认值为空列表")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: []")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自动创建键，并添加元素到列表中")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# defaultdict(<class 'list'>, {'a': [1], 'b': [2]})")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n【5】collections.namedtuple()\ncollections.namedtuple() 是 Python 标准库中的一个函数，用于创建具有命名字段的元组（named tuple）。\n它提供了一种方便的方式来定义具有可读性和自描述性的数据结构。\ncollections.namedtuple() 的一些重要特性和用法：\n--1、定义命名元组：namedtuple() \n接受两个参数，第一个参数是命名元组的名称，第二个参数是元组字段的名称，可以是字符串或字符串列表。\n它返回一个新的元组子类，该子类具有指定的名称和字段。\n\n--2、可读性和自描述性：\n通过为元组字段命名，可以明确指定每个字段的含义和用途，从而提高代码的可读性和自描述性。\n可以通过字段名称而不是索引来访问元组的值。\n\n--3、字段访问：\n创建的命名元组类具有与指定字段名称相对应的属性和方法。可以使用点符号访问字段的值，也可以使用索引访问。\n\n--4、不可变性：命名元组是不可变的，即创建后不能修改元组的值。这与普通元组的行为相同。\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" namedtuple\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 定义命名元组类 Point，包含字段 x 和 y")]),s._v("\nPoint "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" namedtuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Point'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'x'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'y'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建 Point 类的实例")]),s._v("\np1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Point"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问字段的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 2")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用索引访问字段的值")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 2")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建另一个 Point 类的实例")]),s._v("\np2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Point"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 字段访问和索引访问是等价的")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 4")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("p2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 3")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 命名元组是不可变的")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# p1.x = 5  # 会引发 AttributeError")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 迭代命名元组的字段")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" field "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" p1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 1 2")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n【6】collections.OrderedDict\ncollections.OrderedDict 是 Python 标准库中的一个字典类，它是一个有序字典，可以按照元素添加的顺序进行迭代。\n与普通的字典不同，OrderedDict 会记住元素的添加顺序，并在迭代时按照该顺序返回键值对。\n\ncollections.OrderedDict 的一些重要特性和用法：\n--1、保持元素顺序：OrderedDict 会记录元素的添加顺序，因此在迭代字典时，键值对的顺序将与添加顺序保持一致。\n--2、可用作 LRU 缓存：由于 OrderedDict 保留了元素的添加顺序，它可以用于实现 LRU（最近最少使用）缓存。\n通过设置最大容量，当字典达到容量上限时，最早添加的元素将被自动删除。\n--3、与普通字典兼容：OrderedDict 的行为与普通字典完全一致，因此你可以像使用普通字典一样使用它。它支持常见的字典操作，如访问键、设置键值对、删除键等。\n"""')]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" OrderedDict\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建有序字典")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" OrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加键值对")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 迭代有序字典")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# a 1")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# b 2")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# c 3")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问键值对")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 2")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 删除键值对")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("del")]),s._v(" d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# OrderedDict([('b', 2), ('c', 3)])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 作为 LRU 缓存使用")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" OrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("move_to_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 将 'a' 移动到字典的末尾")]),s._v("\nd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加新元素，可能导致最早添加的元素被删除")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# OrderedDict([('b', 2), ('c', 3), ('d', 4)])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建有序字典时保持元素顺序")]),s._v("\nd "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" OrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# OrderedDict([('a', 1), ('b', 2), ('c', 3)])")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\ncollections.UserDict 是一个方便的基类，用于创建自定义字典类。\n它是 Python 标准库中的一个容器类，提供了一个可继承的字典实现，使创建自定义字典变得更加简单和灵活。\nUserDict 的主要目的是作为自定义字典类的基类，通过继承它，可以轻松地扩展和定制字典类的行为。\n相比直接继承内置的 dict 类，使用 UserDict 可以避免一些潜在的问题，并提供了一些方便的方法和属性。\n\ncollections.UserDict 的一些重要特性和用法：\n--1、可继承性：UserDict 提供了一个可继承的字典实现，用于创建自定义的字典类。\n通过继承 UserDict，可以轻松地自定义字典类的行为，添加额外的方法和属性，以满足特定的需求。\n--2、更安全的修改：与直接继承 dict 不同，UserDict 的内部实际上使用了一个普通的字典对象来存储数据，而不是继承 dict。\n这意味着在修改字典时，UserDict 中的方法会直接操作存储数据的字典对象，从而避免了一些潜在的问题，如无限递归。\n--3、方便的扩展：UserDict 提供了一些方便的方法和属性，\n如 data 属性用于访问底层的字典对象，keys()、values()、items() 方法用于返回字典的键、值和键值对。\n这些方法和属性使得自定义字典类的扩展更加简单和一致。\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" UserDict\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyDict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("UserDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__setitem__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在设置键值对时，将值都转换为大写")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__setitem__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("upper"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get_keys")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回字典的键列表，按照字母顺序排序")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sorted")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("keys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建自定义字典对象")]),s._v("\nmy_dict "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MyDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加键值对")]),s._v("\nmy_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'apple'")]),s._v("\nmy_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'banana'")]),s._v("\nmy_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cherry'")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 打印字典的键列表")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("my_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_keys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: ['A', 'B', 'C']")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 打印字典的键值对")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" my_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出:")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# a APPLE")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# b BANANA")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# c CHERRY")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n如何理解无限递归？\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BadDict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__setitem__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("upper"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 错误的做法，会导致无限递归")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n    在上面的代码中，我们定义了一个名为 BadDict 的类，它直接继承了内置的 dict 类，并重写了 __setitem__() 方法。在这个方法中，\n    我们试图将键对应的值转换为大写，并将其保存到字典中。然而，这个实现是错误的。当我们在 __setitem__() 方法内部通过 self[key] 赋值时，\n    实际上会再次调用 __setitem__() 方法，这样就形成了无限递归。每次调用 __setitem__() 方法都会导致新的递归调用，最终导致栈溢出错误。\n    这是因为直接继承 dict 类时，我们在方法内部使用了相同的方法名 __setitem__()，从而覆盖了父类的方法。\n    当我们尝试通过 self[key] 进行赋值时，会再次调用自身的 __setitem__() 方法，而不是父类的方法\n    """')]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\ncollections.UserList \n是 Python 标准库中的一个容器类，它提供了一个可继承的列表实现，用于创建自定义的列表类。\nUserList 允许开发人员通过继承来定制列表类的行为，并提供了一些方便的方法和属性。\n\ncollections.UserList 的一些重要特性和用法：\n--1-可继承性：UserList 提供了一个可继承的列表实现，用于创建自定义的列表类。\n通过继承 UserList，可以轻松地自定义列表类的行为，添加额外的方法和属性，以满足特定的需求。\n--2-更安全的修改：与直接继承内置的 list 类不同，UserList 的内部实际上使用了一个普通的列表对象来存储数据，而不是继承 list。\n这意味着在修改列表时，UserList 中的方法会直接操作存储数据的列表对象，从而避免了一些潜在的问题，如无限递归。\n--3-方便的扩展：UserList 提供了一些方便的方法和属性，\n如 data 属性用于访问底层的列表对象，append()、extend()、insert() 等方法用于修改列表的内容。这些方法和属性使得自定义列表类的扩展更加简单和一致。\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" UserList\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyList")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("UserList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("append")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 在添加元素时，将元素转换为大写")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("upper"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get_unique")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回列表中的唯一元素")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("set")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建自定义列表对象")]),s._v("\nmy_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MyList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 添加元素")]),s._v("\nmy_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'apple'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmy_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'banana'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmy_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cherry'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmy_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extend"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'apple'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'date'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'banana'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 打印列表")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("my_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: ['APPLE', 'BANANA', 'CHERRY', 'APPLE', 'DATE', 'BANANA']")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 打印列表中的唯一元素")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("my_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_unique"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: ['APPLE', 'CHERRY', 'BANANA', 'DATE']")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\nUserString 是一个可继承的字符串类，它允许开发人员通过继承来创建自定义的字符串类，并添加额外的行为和功能。\n通过继承 UserString，我们可以以更灵活的方式处理字符串数据，而无需直接操作字符串对象。\n\nUserString 的一些重要特性和用法：\n\n--1、可继承性：UserString 提供了一个可继承的字符串实现，使开发人员能够创建自定义的字符串类。\n通过继承 UserString，可以轻松地自定义字符串类的行为，添加额外的方法和属性，以满足特定的需求。\n\n--2、安全的修改：与直接继承内置的字符串类不同，UserString 内部使用了一个普通的字符串对象来存储数据，而不是继承字符串类。\n这样，在修改字符串时，UserString 中的方法会直接操作存储数据的字符串对象，从而避免了潜在的问题。\n\n--3、方便的扩展：UserString 提供了一些方便的方法和属性，如 data 属性用于访问底层的字符串对象，\nupper()、lower()、replace() 等方法用于修改字符串的内容。这些方法和属性使得自定义字符串类的扩展更加简单和一\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" collections "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" UserString\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("UserString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("reverse")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回字符串的反转版本")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("count_vowels")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 返回字符串中元音字母的数量")]),s._v("\n        vowels "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'aeiou'")]),s._v("\n        count "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" char "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lower"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" char "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" vowels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                count "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" count\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建自定义字符串对象")]),s._v("\nmy_string "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MyString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Hello, World!"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 调用自定义方法")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("my_string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reverse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('# 输出: "!dlroW ,olleH"')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("my_string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("count_vowels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出: 3")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br"),n("span",{staticClass:"line-number"},[s._v("84")]),n("br"),n("span",{staticClass:"line-number"},[s._v("85")]),n("br"),n("span",{staticClass:"line-number"},[s._v("86")]),n("br"),n("span",{staticClass:"line-number"},[s._v("87")]),n("br"),n("span",{staticClass:"line-number"},[s._v("88")]),n("br"),n("span",{staticClass:"line-number"},[s._v("89")]),n("br"),n("span",{staticClass:"line-number"},[s._v("90")]),n("br"),n("span",{staticClass:"line-number"},[s._v("91")]),n("br"),n("span",{staticClass:"line-number"},[s._v("92")]),n("br"),n("span",{staticClass:"line-number"},[s._v("93")]),n("br"),n("span",{staticClass:"line-number"},[s._v("94")]),n("br"),n("span",{staticClass:"line-number"},[s._v("95")]),n("br"),n("span",{staticClass:"line-number"},[s._v("96")]),n("br"),n("span",{staticClass:"line-number"},[s._v("97")]),n("br"),n("span",{staticClass:"line-number"},[s._v("98")]),n("br"),n("span",{staticClass:"line-number"},[s._v("99")]),n("br"),n("span",{staticClass:"line-number"},[s._v("100")]),n("br"),n("span",{staticClass:"line-number"},[s._v("101")]),n("br"),n("span",{staticClass:"line-number"},[s._v("102")]),n("br"),n("span",{staticClass:"line-number"},[s._v("103")]),n("br"),n("span",{staticClass:"line-number"},[s._v("104")]),n("br"),n("span",{staticClass:"line-number"},[s._v("105")]),n("br"),n("span",{staticClass:"line-number"},[s._v("106")]),n("br"),n("span",{staticClass:"line-number"},[s._v("107")]),n("br"),n("span",{staticClass:"line-number"},[s._v("108")]),n("br"),n("span",{staticClass:"line-number"},[s._v("109")]),n("br"),n("span",{staticClass:"line-number"},[s._v("110")]),n("br"),n("span",{staticClass:"line-number"},[s._v("111")]),n("br"),n("span",{staticClass:"line-number"},[s._v("112")]),n("br"),n("span",{staticClass:"line-number"},[s._v("113")]),n("br"),n("span",{staticClass:"line-number"},[s._v("114")]),n("br"),n("span",{staticClass:"line-number"},[s._v("115")]),n("br"),n("span",{staticClass:"line-number"},[s._v("116")]),n("br"),n("span",{staticClass:"line-number"},[s._v("117")]),n("br"),n("span",{staticClass:"line-number"},[s._v("118")]),n("br"),n("span",{staticClass:"line-number"},[s._v("119")]),n("br"),n("span",{staticClass:"line-number"},[s._v("120")]),n("br"),n("span",{staticClass:"line-number"},[s._v("121")]),n("br"),n("span",{staticClass:"line-number"},[s._v("122")]),n("br"),n("span",{staticClass:"line-number"},[s._v("123")]),n("br"),n("span",{staticClass:"line-number"},[s._v("124")]),n("br"),n("span",{staticClass:"line-number"},[s._v("125")]),n("br"),n("span",{staticClass:"line-number"},[s._v("126")]),n("br"),n("span",{staticClass:"line-number"},[s._v("127")]),n("br"),n("span",{staticClass:"line-number"},[s._v("128")]),n("br"),n("span",{staticClass:"line-number"},[s._v("129")]),n("br"),n("span",{staticClass:"line-number"},[s._v("130")]),n("br"),n("span",{staticClass:"line-number"},[s._v("131")]),n("br"),n("span",{staticClass:"line-number"},[s._v("132")]),n("br"),n("span",{staticClass:"line-number"},[s._v("133")]),n("br"),n("span",{staticClass:"line-number"},[s._v("134")]),n("br"),n("span",{staticClass:"line-number"},[s._v("135")]),n("br"),n("span",{staticClass:"line-number"},[s._v("136")]),n("br"),n("span",{staticClass:"line-number"},[s._v("137")]),n("br"),n("span",{staticClass:"line-number"},[s._v("138")]),n("br"),n("span",{staticClass:"line-number"},[s._v("139")]),n("br"),n("span",{staticClass:"line-number"},[s._v("140")]),n("br"),n("span",{staticClass:"line-number"},[s._v("141")]),n("br"),n("span",{staticClass:"line-number"},[s._v("142")]),n("br"),n("span",{staticClass:"line-number"},[s._v("143")]),n("br"),n("span",{staticClass:"line-number"},[s._v("144")]),n("br"),n("span",{staticClass:"line-number"},[s._v("145")]),n("br"),n("span",{staticClass:"line-number"},[s._v("146")]),n("br"),n("span",{staticClass:"line-number"},[s._v("147")]),n("br"),n("span",{staticClass:"line-number"},[s._v("148")]),n("br"),n("span",{staticClass:"line-number"},[s._v("149")]),n("br"),n("span",{staticClass:"line-number"},[s._v("150")]),n("br"),n("span",{staticClass:"line-number"},[s._v("151")]),n("br"),n("span",{staticClass:"line-number"},[s._v("152")]),n("br"),n("span",{staticClass:"line-number"},[s._v("153")]),n("br"),n("span",{staticClass:"line-number"},[s._v("154")]),n("br"),n("span",{staticClass:"line-number"},[s._v("155")]),n("br"),n("span",{staticClass:"line-number"},[s._v("156")]),n("br"),n("span",{staticClass:"line-number"},[s._v("157")]),n("br"),n("span",{staticClass:"line-number"},[s._v("158")]),n("br"),n("span",{staticClass:"line-number"},[s._v("159")]),n("br"),n("span",{staticClass:"line-number"},[s._v("160")]),n("br"),n("span",{staticClass:"line-number"},[s._v("161")]),n("br"),n("span",{staticClass:"line-number"},[s._v("162")]),n("br"),n("span",{staticClass:"line-number"},[s._v("163")]),n("br"),n("span",{staticClass:"line-number"},[s._v("164")]),n("br"),n("span",{staticClass:"line-number"},[s._v("165")]),n("br"),n("span",{staticClass:"line-number"},[s._v("166")]),n("br"),n("span",{staticClass:"line-number"},[s._v("167")]),n("br"),n("span",{staticClass:"line-number"},[s._v("168")]),n("br"),n("span",{staticClass:"line-number"},[s._v("169")]),n("br"),n("span",{staticClass:"line-number"},[s._v("170")]),n("br"),n("span",{staticClass:"line-number"},[s._v("171")]),n("br"),n("span",{staticClass:"line-number"},[s._v("172")]),n("br"),n("span",{staticClass:"line-number"},[s._v("173")]),n("br"),n("span",{staticClass:"line-number"},[s._v("174")]),n("br"),n("span",{staticClass:"line-number"},[s._v("175")]),n("br"),n("span",{staticClass:"line-number"},[s._v("176")]),n("br"),n("span",{staticClass:"line-number"},[s._v("177")]),n("br"),n("span",{staticClass:"line-number"},[s._v("178")]),n("br"),n("span",{staticClass:"line-number"},[s._v("179")]),n("br"),n("span",{staticClass:"line-number"},[s._v("180")]),n("br"),n("span",{staticClass:"line-number"},[s._v("181")]),n("br"),n("span",{staticClass:"line-number"},[s._v("182")]),n("br"),n("span",{staticClass:"line-number"},[s._v("183")]),n("br"),n("span",{staticClass:"line-number"},[s._v("184")]),n("br"),n("span",{staticClass:"line-number"},[s._v("185")]),n("br"),n("span",{staticClass:"line-number"},[s._v("186")]),n("br"),n("span",{staticClass:"line-number"},[s._v("187")]),n("br"),n("span",{staticClass:"line-number"},[s._v("188")]),n("br"),n("span",{staticClass:"line-number"},[s._v("189")]),n("br"),n("span",{staticClass:"line-number"},[s._v("190")]),n("br"),n("span",{staticClass:"line-number"},[s._v("191")]),n("br"),n("span",{staticClass:"line-number"},[s._v("192")]),n("br"),n("span",{staticClass:"line-number"},[s._v("193")]),n("br"),n("span",{staticClass:"line-number"},[s._v("194")]),n("br"),n("span",{staticClass:"line-number"},[s._v("195")]),n("br"),n("span",{staticClass:"line-number"},[s._v("196")]),n("br"),n("span",{staticClass:"line-number"},[s._v("197")]),n("br"),n("span",{staticClass:"line-number"},[s._v("198")]),n("br"),n("span",{staticClass:"line-number"},[s._v("199")]),n("br"),n("span",{staticClass:"line-number"},[s._v("200")]),n("br"),n("span",{staticClass:"line-number"},[s._v("201")]),n("br"),n("span",{staticClass:"line-number"},[s._v("202")]),n("br"),n("span",{staticClass:"line-number"},[s._v("203")]),n("br"),n("span",{staticClass:"line-number"},[s._v("204")]),n("br"),n("span",{staticClass:"line-number"},[s._v("205")]),n("br"),n("span",{staticClass:"line-number"},[s._v("206")]),n("br"),n("span",{staticClass:"line-number"},[s._v("207")]),n("br"),n("span",{staticClass:"line-number"},[s._v("208")]),n("br"),n("span",{staticClass:"line-number"},[s._v("209")]),n("br"),n("span",{staticClass:"line-number"},[s._v("210")]),n("br"),n("span",{staticClass:"line-number"},[s._v("211")]),n("br"),n("span",{staticClass:"line-number"},[s._v("212")]),n("br"),n("span",{staticClass:"line-number"},[s._v("213")]),n("br"),n("span",{staticClass:"line-number"},[s._v("214")]),n("br"),n("span",{staticClass:"line-number"},[s._v("215")]),n("br"),n("span",{staticClass:"line-number"},[s._v("216")]),n("br"),n("span",{staticClass:"line-number"},[s._v("217")]),n("br"),n("span",{staticClass:"line-number"},[s._v("218")]),n("br"),n("span",{staticClass:"line-number"},[s._v("219")]),n("br"),n("span",{staticClass:"line-number"},[s._v("220")]),n("br"),n("span",{staticClass:"line-number"},[s._v("221")]),n("br"),n("span",{staticClass:"line-number"},[s._v("222")]),n("br"),n("span",{staticClass:"line-number"},[s._v("223")]),n("br"),n("span",{staticClass:"line-number"},[s._v("224")]),n("br"),n("span",{staticClass:"line-number"},[s._v("225")]),n("br"),n("span",{staticClass:"line-number"},[s._v("226")]),n("br"),n("span",{staticClass:"line-number"},[s._v("227")]),n("br"),n("span",{staticClass:"line-number"},[s._v("228")]),n("br"),n("span",{staticClass:"line-number"},[s._v("229")]),n("br"),n("span",{staticClass:"line-number"},[s._v("230")]),n("br"),n("span",{staticClass:"line-number"},[s._v("231")]),n("br"),n("span",{staticClass:"line-number"},[s._v("232")]),n("br"),n("span",{staticClass:"line-number"},[s._v("233")]),n("br"),n("span",{staticClass:"line-number"},[s._v("234")]),n("br"),n("span",{staticClass:"line-number"},[s._v("235")]),n("br"),n("span",{staticClass:"line-number"},[s._v("236")]),n("br"),n("span",{staticClass:"line-number"},[s._v("237")]),n("br"),n("span",{staticClass:"line-number"},[s._v("238")]),n("br"),n("span",{staticClass:"line-number"},[s._v("239")]),n("br"),n("span",{staticClass:"line-number"},[s._v("240")]),n("br"),n("span",{staticClass:"line-number"},[s._v("241")]),n("br"),n("span",{staticClass:"line-number"},[s._v("242")]),n("br"),n("span",{staticClass:"line-number"},[s._v("243")]),n("br"),n("span",{staticClass:"line-number"},[s._v("244")]),n("br"),n("span",{staticClass:"line-number"},[s._v("245")]),n("br"),n("span",{staticClass:"line-number"},[s._v("246")]),n("br"),n("span",{staticClass:"line-number"},[s._v("247")]),n("br"),n("span",{staticClass:"line-number"},[s._v("248")]),n("br"),n("span",{staticClass:"line-number"},[s._v("249")]),n("br"),n("span",{staticClass:"line-number"},[s._v("250")]),n("br"),n("span",{staticClass:"line-number"},[s._v("251")]),n("br"),n("span",{staticClass:"line-number"},[s._v("252")]),n("br"),n("span",{staticClass:"line-number"},[s._v("253")]),n("br"),n("span",{staticClass:"line-number"},[s._v("254")]),n("br"),n("span",{staticClass:"line-number"},[s._v("255")]),n("br"),n("span",{staticClass:"line-number"},[s._v("256")]),n("br"),n("span",{staticClass:"line-number"},[s._v("257")]),n("br"),n("span",{staticClass:"line-number"},[s._v("258")]),n("br"),n("span",{staticClass:"line-number"},[s._v("259")]),n("br"),n("span",{staticClass:"line-number"},[s._v("260")]),n("br"),n("span",{staticClass:"line-number"},[s._v("261")]),n("br"),n("span",{staticClass:"line-number"},[s._v("262")]),n("br"),n("span",{staticClass:"line-number"},[s._v("263")]),n("br"),n("span",{staticClass:"line-number"},[s._v("264")]),n("br"),n("span",{staticClass:"line-number"},[s._v("265")]),n("br"),n("span",{staticClass:"line-number"},[s._v("266")]),n("br"),n("span",{staticClass:"line-number"},[s._v("267")]),n("br"),n("span",{staticClass:"line-number"},[s._v("268")]),n("br"),n("span",{staticClass:"line-number"},[s._v("269")]),n("br"),n("span",{staticClass:"line-number"},[s._v("270")]),n("br"),n("span",{staticClass:"line-number"},[s._v("271")]),n("br"),n("span",{staticClass:"line-number"},[s._v("272")]),n("br"),n("span",{staticClass:"line-number"},[s._v("273")]),n("br"),n("span",{staticClass:"line-number"},[s._v("274")]),n("br"),n("span",{staticClass:"line-number"},[s._v("275")]),n("br"),n("span",{staticClass:"line-number"},[s._v("276")]),n("br"),n("span",{staticClass:"line-number"},[s._v("277")]),n("br"),n("span",{staticClass:"line-number"},[s._v("278")]),n("br"),n("span",{staticClass:"line-number"},[s._v("279")]),n("br"),n("span",{staticClass:"line-number"},[s._v("280")]),n("br"),n("span",{staticClass:"line-number"},[s._v("281")]),n("br"),n("span",{staticClass:"line-number"},[s._v("282")]),n("br"),n("span",{staticClass:"line-number"},[s._v("283")]),n("br"),n("span",{staticClass:"line-number"},[s._v("284")]),n("br"),n("span",{staticClass:"line-number"},[s._v("285")]),n("br"),n("span",{staticClass:"line-number"},[s._v("286")]),n("br"),n("span",{staticClass:"line-number"},[s._v("287")]),n("br"),n("span",{staticClass:"line-number"},[s._v("288")]),n("br"),n("span",{staticClass:"line-number"},[s._v("289")]),n("br"),n("span",{staticClass:"line-number"},[s._v("290")]),n("br"),n("span",{staticClass:"line-number"},[s._v("291")]),n("br"),n("span",{staticClass:"line-number"},[s._v("292")]),n("br"),n("span",{staticClass:"line-number"},[s._v("293")]),n("br"),n("span",{staticClass:"line-number"},[s._v("294")]),n("br"),n("span",{staticClass:"line-number"},[s._v("295")]),n("br"),n("span",{staticClass:"line-number"},[s._v("296")]),n("br"),n("span",{staticClass:"line-number"},[s._v("297")]),n("br"),n("span",{staticClass:"line-number"},[s._v("298")]),n("br"),n("span",{staticClass:"line-number"},[s._v("299")]),n("br"),n("span",{staticClass:"line-number"},[s._v("300")]),n("br"),n("span",{staticClass:"line-number"},[s._v("301")]),n("br"),n("span",{staticClass:"line-number"},[s._v("302")]),n("br"),n("span",{staticClass:"line-number"},[s._v("303")]),n("br"),n("span",{staticClass:"line-number"},[s._v("304")]),n("br"),n("span",{staticClass:"line-number"},[s._v("305")]),n("br"),n("span",{staticClass:"line-number"},[s._v("306")]),n("br"),n("span",{staticClass:"line-number"},[s._v("307")]),n("br"),n("span",{staticClass:"line-number"},[s._v("308")]),n("br"),n("span",{staticClass:"line-number"},[s._v("309")]),n("br"),n("span",{staticClass:"line-number"},[s._v("310")]),n("br"),n("span",{staticClass:"line-number"},[s._v("311")]),n("br"),n("span",{staticClass:"line-number"},[s._v("312")]),n("br"),n("span",{staticClass:"line-number"},[s._v("313")]),n("br"),n("span",{staticClass:"line-number"},[s._v("314")]),n("br"),n("span",{staticClass:"line-number"},[s._v("315")]),n("br"),n("span",{staticClass:"line-number"},[s._v("316")]),n("br"),n("span",{staticClass:"line-number"},[s._v("317")]),n("br"),n("span",{staticClass:"line-number"},[s._v("318")]),n("br"),n("span",{staticClass:"line-number"},[s._v("319")]),n("br"),n("span",{staticClass:"line-number"},[s._v("320")]),n("br"),n("span",{staticClass:"line-number"},[s._v("321")]),n("br"),n("span",{staticClass:"line-number"},[s._v("322")]),n("br"),n("span",{staticClass:"line-number"},[s._v("323")]),n("br"),n("span",{staticClass:"line-number"},[s._v("324")]),n("br"),n("span",{staticClass:"line-number"},[s._v("325")]),n("br"),n("span",{staticClass:"line-number"},[s._v("326")]),n("br"),n("span",{staticClass:"line-number"},[s._v("327")]),n("br"),n("span",{staticClass:"line-number"},[s._v("328")]),n("br"),n("span",{staticClass:"line-number"},[s._v("329")]),n("br"),n("span",{staticClass:"line-number"},[s._v("330")]),n("br"),n("span",{staticClass:"line-number"},[s._v("331")]),n("br"),n("span",{staticClass:"line-number"},[s._v("332")]),n("br"),n("span",{staticClass:"line-number"},[s._v("333")]),n("br"),n("span",{staticClass:"line-number"},[s._v("334")]),n("br"),n("span",{staticClass:"line-number"},[s._v("335")]),n("br"),n("span",{staticClass:"line-number"},[s._v("336")]),n("br"),n("span",{staticClass:"line-number"},[s._v("337")]),n("br"),n("span",{staticClass:"line-number"},[s._v("338")]),n("br"),n("span",{staticClass:"line-number"},[s._v("339")]),n("br"),n("span",{staticClass:"line-number"},[s._v("340")]),n("br"),n("span",{staticClass:"line-number"},[s._v("341")]),n("br"),n("span",{staticClass:"line-number"},[s._v("342")]),n("br"),n("span",{staticClass:"line-number"},[s._v("343")]),n("br"),n("span",{staticClass:"line-number"},[s._v("344")]),n("br"),n("span",{staticClass:"line-number"},[s._v("345")]),n("br"),n("span",{staticClass:"line-number"},[s._v("346")]),n("br"),n("span",{staticClass:"line-number"},[s._v("347")]),n("br"),n("span",{staticClass:"line-number"},[s._v("348")]),n("br"),n("span",{staticClass:"line-number"},[s._v("349")]),n("br"),n("span",{staticClass:"line-number"},[s._v("350")]),n("br"),n("span",{staticClass:"line-number"},[s._v("351")]),n("br"),n("span",{staticClass:"line-number"},[s._v("352")]),n("br"),n("span",{staticClass:"line-number"},[s._v("353")]),n("br"),n("span",{staticClass:"line-number"},[s._v("354")]),n("br"),n("span",{staticClass:"line-number"},[s._v("355")]),n("br"),n("span",{staticClass:"line-number"},[s._v("356")]),n("br"),n("span",{staticClass:"line-number"},[s._v("357")]),n("br"),n("span",{staticClass:"line-number"},[s._v("358")]),n("br"),n("span",{staticClass:"line-number"},[s._v("359")]),n("br"),n("span",{staticClass:"line-number"},[s._v("360")]),n("br"),n("span",{staticClass:"line-number"},[s._v("361")]),n("br"),n("span",{staticClass:"line-number"},[s._v("362")]),n("br"),n("span",{staticClass:"line-number"},[s._v("363")]),n("br"),n("span",{staticClass:"line-number"},[s._v("364")]),n("br"),n("span",{staticClass:"line-number"},[s._v("365")]),n("br"),n("span",{staticClass:"line-number"},[s._v("366")]),n("br"),n("span",{staticClass:"line-number"},[s._v("367")]),n("br"),n("span",{staticClass:"line-number"},[s._v("368")]),n("br"),n("span",{staticClass:"line-number"},[s._v("369")]),n("br"),n("span",{staticClass:"line-number"},[s._v("370")]),n("br"),n("span",{staticClass:"line-number"},[s._v("371")]),n("br"),n("span",{staticClass:"line-number"},[s._v("372")]),n("br"),n("span",{staticClass:"line-number"},[s._v("373")]),n("br"),n("span",{staticClass:"line-number"},[s._v("374")]),n("br"),n("span",{staticClass:"line-number"},[s._v("375")]),n("br"),n("span",{staticClass:"line-number"},[s._v("376")]),n("br"),n("span",{staticClass:"line-number"},[s._v("377")]),n("br"),n("span",{staticClass:"line-number"},[s._v("378")]),n("br"),n("span",{staticClass:"line-number"},[s._v("379")]),n("br"),n("span",{staticClass:"line-number"},[s._v("380")]),n("br"),n("span",{staticClass:"line-number"},[s._v("381")]),n("br"),n("span",{staticClass:"line-number"},[s._v("382")]),n("br"),n("span",{staticClass:"line-number"},[s._v("383")]),n("br"),n("span",{staticClass:"line-number"},[s._v("384")]),n("br"),n("span",{staticClass:"line-number"},[s._v("385")]),n("br"),n("span",{staticClass:"line-number"},[s._v("386")]),n("br"),n("span",{staticClass:"line-number"},[s._v("387")]),n("br"),n("span",{staticClass:"line-number"},[s._v("388")]),n("br"),n("span",{staticClass:"line-number"},[s._v("389")]),n("br"),n("span",{staticClass:"line-number"},[s._v("390")]),n("br"),n("span",{staticClass:"line-number"},[s._v("391")]),n("br"),n("span",{staticClass:"line-number"},[s._v("392")]),n("br"),n("span",{staticClass:"line-number"},[s._v("393")]),n("br"),n("span",{staticClass:"line-number"},[s._v("394")]),n("br"),n("span",{staticClass:"line-number"},[s._v("395")]),n("br"),n("span",{staticClass:"line-number"},[s._v("396")]),n("br"),n("span",{staticClass:"line-number"},[s._v("397")]),n("br"),n("span",{staticClass:"line-number"},[s._v("398")]),n("br"),n("span",{staticClass:"line-number"},[s._v("399")]),n("br"),n("span",{staticClass:"line-number"},[s._v("400")]),n("br"),n("span",{staticClass:"line-number"},[s._v("401")]),n("br"),n("span",{staticClass:"line-number"},[s._v("402")]),n("br"),n("span",{staticClass:"line-number"},[s._v("403")]),n("br"),n("span",{staticClass:"line-number"},[s._v("404")]),n("br"),n("span",{staticClass:"line-number"},[s._v("405")]),n("br"),n("span",{staticClass:"line-number"},[s._v("406")]),n("br"),n("span",{staticClass:"line-number"},[s._v("407")]),n("br"),n("span",{staticClass:"line-number"},[s._v("408")]),n("br"),n("span",{staticClass:"line-number"},[s._v("409")]),n("br"),n("span",{staticClass:"line-number"},[s._v("410")]),n("br"),n("span",{staticClass:"line-number"},[s._v("411")]),n("br"),n("span",{staticClass:"line-number"},[s._v("412")]),n("br"),n("span",{staticClass:"line-number"},[s._v("413")]),n("br"),n("span",{staticClass:"line-number"},[s._v("414")]),n("br"),n("span",{staticClass:"line-number"},[s._v("415")]),n("br"),n("span",{staticClass:"line-number"},[s._v("416")]),n("br"),n("span",{staticClass:"line-number"},[s._v("417")]),n("br"),n("span",{staticClass:"line-number"},[s._v("418")]),n("br"),n("span",{staticClass:"line-number"},[s._v("419")]),n("br"),n("span",{staticClass:"line-number"},[s._v("420")]),n("br"),n("span",{staticClass:"line-number"},[s._v("421")]),n("br"),n("span",{staticClass:"line-number"},[s._v("422")]),n("br"),n("span",{staticClass:"line-number"},[s._v("423")]),n("br"),n("span",{staticClass:"line-number"},[s._v("424")]),n("br"),n("span",{staticClass:"line-number"},[s._v("425")]),n("br"),n("span",{staticClass:"line-number"},[s._v("426")]),n("br"),n("span",{staticClass:"line-number"},[s._v("427")]),n("br"),n("span",{staticClass:"line-number"},[s._v("428")]),n("br"),n("span",{staticClass:"line-number"},[s._v("429")]),n("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);